# AI chat interface
===
Abstract:001
## Papar Information
- Title:  `OpenLLM chat interface`
- Authors:  `Douglas Caron`
- Preprint: [https://arxiv.org/abs/2308.07317](https://arxiv.org/abs/2308.07317)

## Install & Dependence
- python
- openllm
- model of your choice

<!-- ## Dataset Preparation
| Dataset | Download |
| ---     | ---   |
| dataset-A | [download]() |
| dataset-B | [download]() |
| dataset-C | [download]() | -->

## Use
- for ai model
  ```
  openllm start *model name here*
  e.g: `openllm start opt`
  ```
- for program link (easy interface)
  ```
  python main.py
  ```

## Available CPU only models
| Model | Download |
| ---     | ---   |
| chatglm | [Download]() |
| dolly-v2 | [Download]() |
| flan-t5 | [Download]() |
| llama | [Download]() |
| mpt | [Download]() |
| opt | [Download]() |
| stablelm | [Download]() |

## Available GPU models
| Model | Download |
| --- | --- |
| chatglm | [Download]() |
| dolly-v2 | [Download]() |
| falcon | [Download]() |
| flan-t5 | [Download]() |
| gpt-neox | [Download]() |
| llama | [Download]() |
| mpt | [Download]() |
| opt | [Download]() |
| stablelm | [Download]() |
| starcoder | [Download]() |
| baichuan | [Download]() |

## Directory Hierarchy
```
|—— ai
|    |—— main.py
|    |—— readme.md
```
## Code Details
### Tested Platform
- software
  ```
  OS: Debian unstable (May 2021), Ubuntu LTS
  Python: 3.8.5 (anaconda)
  PyTorch: 1.7.1, 1.8.1
  ```
- hardware
  ```
  CPU: Intel Xeon 6226R
  GPU: Nvidia RTX3090 (24GB)
  ```
### Hyper parameters
```
```
## References
- [openllm](https://github.com/bentoml/OpenLLM)
  